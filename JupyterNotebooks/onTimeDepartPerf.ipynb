{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = sc.textFile('file:///C:/Users/Ashwini/Desktop/onTimeDepartPerf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2965"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ABE', '9E', '6.771714922048997'],\n",
       " ['ABE', 'AA', '4.630407124681934'],\n",
       " ['ABE', 'DH', '5.356243252968694'],\n",
       " ['ABE', 'DL', '23.120029967356984'],\n",
       " ['ABE', 'EA', '6.578622482131254'],\n",
       " ['ABE', 'EV', '15.46139963906156'],\n",
       " ['ABE', 'NW', '1.8226794590220783'],\n",
       " ['ABE', 'OH', '6.53022997032641'],\n",
       " ['ABE', 'OO', '10.096487686717804'],\n",
       " ['ABE', 'PI', '5.016528925619835']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = file.map(lambda line:line.split()).filter(lambda line:len(line)==3)\n",
    "file.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = file.map(lambda tuple:(tuple[0],tuple[1],float(tuple[2])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2882"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "rdd = file1.map(lambda row: Row(airport=row[0], carrier=row[1], dep_delay=row[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------------------+\n",
      "|airport|carrier|          dep_delay|\n",
      "+-------+-------+-------------------+\n",
      "|    ABE|     9E|  6.771714922048997|\n",
      "|    ABE|     AA|  4.630407124681934|\n",
      "|    ABE|     DH|  5.356243252968694|\n",
      "|    ABE|     DL| 23.120029967356984|\n",
      "|    ABE|     EA|  6.578622482131254|\n",
      "|    ABE|     EV|  15.46139963906156|\n",
      "|    ABE|     NW| 1.8226794590220783|\n",
      "|    ABE|     OH|   6.53022997032641|\n",
      "|    ABE|     OO| 10.096487686717804|\n",
      "|    ABE|     PI|  5.016528925619835|\n",
      "|    ABE|     TW|  2.002008032128514|\n",
      "|    ABE|     UA|  8.764681724845996|\n",
      "|    ABE|     US| 2.6949712267852473|\n",
      "|    ABE|     XE|-3.8152038454691115|\n",
      "|    ABE|     YV| 21.996439697374278|\n",
      "|    ABI|     EV|               1.75|\n",
      "|    ABI|     MQ|  3.869399156310569|\n",
      "|    ABI|     OO|  6.579889807162535|\n",
      "|    ABI|     US|                0.0|\n",
      "|    ABI|     XE| -4.604166666666667|\n",
      "+-------+-------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import ceil, col,round\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster(['127.0.0.1'])  # provide contact points and port\n",
    "session = cluster.connect('aviation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.select(\"airport\",\"carrier\",round(col('dep_delay'),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------------------+\n",
      "|airport|carrier|round(dep_delay, 4)|\n",
      "+-------+-------+-------------------+\n",
      "|    ABE|     9E|             6.7717|\n",
      "|    ABE|     AA|             4.6304|\n",
      "|    ABE|     DH|             5.3562|\n",
      "|    ABE|     DL|              23.12|\n",
      "|    ABE|     EA|             6.5786|\n",
      "|    ABE|     EV|            15.4614|\n",
      "|    ABE|     NW|             1.8227|\n",
      "|    ABE|     OH|             6.5302|\n",
      "|    ABE|     OO|            10.0965|\n",
      "|    ABE|     PI|             5.0165|\n",
      "|    ABE|     TW|              2.002|\n",
      "|    ABE|     UA|             8.7647|\n",
      "|    ABE|     US|              2.695|\n",
      "|    ABE|     XE|            -3.8152|\n",
      "|    ABE|     YV|            21.9964|\n",
      "|    ABI|     EV|               1.75|\n",
      "|    ABI|     MQ|             3.8694|\n",
      "|    ABI|     OO|             6.5799|\n",
      "|    ABI|     US|                0.0|\n",
      "|    ABI|     XE|            -4.6042|\n",
      "+-------+-------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 =df1.withColumnRenamed(\"round(dep_delay, 4)\",\"dep_delay\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+\n",
      "|airport|carrier|dep_delay|\n",
      "+-------+-------+---------+\n",
      "|    ABE|     9E|   6.7717|\n",
      "|    ABE|     AA|   4.6304|\n",
      "|    ABE|     DH|   5.3562|\n",
      "|    ABE|     DL|    23.12|\n",
      "|    ABE|     EA|   6.5786|\n",
      "|    ABE|     EV|  15.4614|\n",
      "|    ABE|     NW|   1.8227|\n",
      "|    ABE|     OH|   6.5302|\n",
      "|    ABE|     OO|  10.0965|\n",
      "|    ABE|     PI|   5.0165|\n",
      "|    ABE|     TW|    2.002|\n",
      "|    ABE|     UA|   8.7647|\n",
      "|    ABE|     US|    2.695|\n",
      "|    ABE|     XE|  -3.8152|\n",
      "|    ABE|     YV|  21.9964|\n",
      "|    ABI|     EV|     1.75|\n",
      "|    ABI|     MQ|   3.8694|\n",
      "|    ABI|     OO|   6.5799|\n",
      "|    ABI|     US|      0.0|\n",
      "|    ABI|     XE|  -4.6042|\n",
      "+-------+-------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.write\\\n",
    ".format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".mode('append')\\\n",
    ".options(table = \"carrier_depart_delay\", keyspace = \"aviation\")  \\\n",
    ".save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= ds = sqlContext.read \\\n",
    "  .format('org.apache.spark.sql.cassandra') \\\n",
    "  .options(table='carrier_depart_delay', keyspace='aviation') \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------+\n",
      "|airport|           dep_delay|carrier|\n",
      "+-------+--------------------+-------+\n",
      "|    LYH|6.858600000000000000|     EV|\n",
      "|    LYH|5.754900000000000000|     PI|\n",
      "|    LYH|2.895000000000000000|     US|\n",
      "|    CRW|16.60420000000000...|     OO|\n",
      "|    CRW|12.62950000000000...|     EV|\n",
      "|    CRW|8.560000000000000000|     YV|\n",
      "|    CRW|5.742200000000000000|     PI|\n",
      "|    CRW|5.238400000000000000|     US|\n",
      "|    CRW|4.631900000000000000|     DH|\n",
      "|    CRW|4.419300000000000000|     XE|\n",
      "|    CRW|2.731700000000000000|     OH|\n",
      "|    CRW|-0.13330000000000...|     UA|\n",
      "|    CRW|-0.14150000000000...|     9E|\n",
      "|    MFR|17.07430000000000...|     CO|\n",
      "|    MFR|12.04590000000000...|     UA|\n",
      "|    MFR|8.538000000000000000|     OO|\n",
      "|    MFR|8.379900000000000000|     PS|\n",
      "|    MFR|6.500800000000000000|     US|\n",
      "|    MFR|4.050700000000000000|     YV|\n",
      "|    ISP|18.02280000000000...|     EV|\n",
      "+-------+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
